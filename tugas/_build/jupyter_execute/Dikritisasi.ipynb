{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHh9Nm8fL5pu"
   },
   "source": [
    "# **KMeans Diskritisasi dan Klasifikasi**\n",
    "\n",
    "Proses ini melibatkan dua tahap besar:\n",
    "1. Diskritisasi menggunakan K-Means\n",
    "\n",
    "2. Klasifikasi dengan Naive Bayes dan Decision Tree, baik sebelum maupun sesudah diskritisasi.\n",
    "\n",
    "##üí° 1. Diskritisasi dengan K-Means\n",
    "Apa itu Diskritisasi?\n",
    "Diskritisasi adalah proses mengubah fitur numerik menjadi fitur kategorik (diskrit). Misalnya, panjang sepal menjadi kelas \"pendek\", \"sedang\", \"panjang\".\n",
    "\n",
    "Kenapa K-Means?\n",
    "K-Means digunakan untuk mencari natural groupings dalam data numerik. Hasil klasternya dianggap sebagai kategori diskrit.\n",
    "\n",
    "Contoh Proses pada Data Iris:\n",
    "Data Iris memiliki 4 fitur numerik:\n",
    "\n",
    "* sepal length\n",
    "\n",
    "* sepal width\n",
    "\n",
    "* petal length\n",
    "\n",
    "* petal width\n",
    "\n",
    "Langkah-langkah:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "timBMGhrLllp",
    "outputId": "7806a7ec-34f4-49df-9805-743c8f2c198f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m uploaded = files.upload()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Load dari CSV\n",
    "df = pd.read_csv('default_iris_combined.csv')\n",
    "\n",
    "# Pisahkan fitur dan target\n",
    "X = df.drop(['id', 'class'], axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Diskritisasi dengan KMeans untuk masing-masing fitur (contoh 3 klaster)\n",
    "X_discretized = X.copy()\n",
    "for col in X.columns:\n",
    "    km = KMeans(n_clusters=3, random_state=42)\n",
    "    X_discretized[col] = km.fit_predict(X[[col]])\n",
    "\n",
    "# Data sudah diskrit\n",
    "print(X_discretized.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ulja7ObMwZs"
   },
   "source": [
    "## ‚öôÔ∏è 2. Klasifikasi Sebelum dan Sesudah Diskritisasi\n",
    "###A. Sebelum Diskritisasi (Data Asli - Numerik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PTadfUaM8x6",
    "outputId": "6edb8473-77c4-4d10-c194-6bf0ebd991a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes (Numerik) ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       1.00      1.00      1.00        11\n",
      " Iris-virginica       1.00      1.00      1.00        12\n",
      "\n",
      "       accuracy                           1.00        38\n",
      "      macro avg       1.00      1.00      1.00        38\n",
      "   weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "=== Decision Tree (Numerik) ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       1.00      1.00      1.00        11\n",
      " Iris-virginica       1.00      1.00      1.00        12\n",
      "\n",
      "       accuracy                           1.00        38\n",
      "      macro avg       1.00      1.00      1.00        38\n",
      "   weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Model Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Model Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"=== Naive Bayes (Numerik) ===\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"=== Decision Tree (Numerik) ===\")\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "el6UAhKuNAOz"
   },
   "source": [
    "### B. Setelah Diskritisasi (Data Kategorik)\n",
    "Untuk Naive Bayes, kita gunakan CategoricalNB dari sklearn karena datanya diskrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEAm4vKUNM78",
    "outputId": "a04d5153-4608-46de-99e3-137b3712c0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Categorical Naive Bayes (Diskrit) ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       1.00      1.00      1.00        11\n",
      " Iris-virginica       1.00      1.00      1.00        12\n",
      "\n",
      "       accuracy                           1.00        38\n",
      "      macro avg       1.00      1.00      1.00        38\n",
      "   weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "=== Decision Tree (Diskrit) ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        15\n",
      "Iris-versicolor       1.00      1.00      1.00        11\n",
      " Iris-virginica       1.00      1.00      1.00        12\n",
      "\n",
      "       accuracy                           1.00        38\n",
      "      macro avg       1.00      1.00      1.00        38\n",
      "   weighted avg       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "# Split diskrit\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_discretized, y, random_state=42)\n",
    "\n",
    "# Naive Bayes Diskrit\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train_d, y_train_d)\n",
    "y_pred_cnb = cnb.predict(X_test_d)\n",
    "\n",
    "# Decision Tree Diskrit (bisa pakai model yg sama)\n",
    "dt2 = DecisionTreeClassifier(random_state=42)\n",
    "dt2.fit(X_train_d, y_train_d)\n",
    "y_pred_dt2 = dt2.predict(X_test_d)\n",
    "\n",
    "print(\"=== Categorical Naive Bayes (Diskrit) ===\")\n",
    "print(classification_report(y_test_d, y_pred_cnb))\n",
    "\n",
    "print(\"=== Decision Tree (Diskrit) ===\")\n",
    "print(classification_report(y_test_d, y_pred_dt2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thqtplYWNRDv"
   },
   "source": [
    "## üìä Kesimpulan Analisis:\n",
    "Setelah kamu menjalankan semua kode:\n",
    "\n",
    "| Model                       | Data Asli (Numerik)    | Data Diskrit (KMeans)    |\n",
    "| --------------------------- | ---------------------- | ------------------------ |\n",
    "| Naive Bayes (`GaussianNB`)  | Akurasi tinggi         | Tidak cocok              |\n",
    "| Naive Bayes (`Categorical`) | -                      | Cocok untuk data diskrit |\n",
    "| Decision Tree               | Cocok untuk dua-duanya |                          |\n",
    "\n",
    "Catatan:\n",
    "* GaussianNB mengasumsikan distribusi normal pada fitur numerik, jadi tidak cocok untuk data diskrit.\n",
    "\n",
    "* CategoricalNB cocok untuk data hasil diskritisasi.\n",
    "\n",
    "* Decision Tree bisa pakai dua-duanya."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}